{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jzHyvIBUKHaJxwmWG2UikvPM0p8kFoDU",
      "authorship_tag": "ABX9TyOEckjDELu+S8J9pmKijUX9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "it8nnRlEBTyk"
      },
      "source": [
        "#import libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.tensorboard as tb\n",
        "import torch.utils.data as data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p7d4CA9CZ0Y"
      },
      "source": [
        "!pip install wandb\n",
        "!wandb login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKz7f5z-CcTh"
      },
      "source": [
        "import wandb\n",
        "wandb.init(project=\"CNN\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJt_5VqICgB2"
      },
      "source": [
        "class ClassificationMetrics:\n",
        "  def __init__(self, num_classes=10):\n",
        "    self.num_classes = num_classes\n",
        "    self.C = torch.zeros(num_classes, num_classes) \n",
        "    self.C=self.C.cuda()\n",
        "\n",
        "  def add(self, yp, yt):\n",
        "    with torch.no_grad():\n",
        "      self.C+=(yt*self.C.shape[1]+yp).bincount(minlength=self.C.numel()).view(self.C.shape).float()\n",
        "\n",
        "  def clear(self):\n",
        "    self.C.zero_()\n",
        "\n",
        "  def acc(self):\n",
        "    return self.C.diag().sum().item()/self.C.sum()\n",
        "\n",
        "  def mAcc(self):\n",
        "    return (self.C.diag()/self.C.sum(-1)).mean().item()\n",
        "\n",
        "  def mIoU(self):\n",
        "    return (self.C.diag()/(self.C.sum(0)+self.C.sum(1)-self.C.diag())).mean().item()\n",
        "\n",
        "  def confusion_matrix(self):\n",
        "    return self.C\n",
        "    \n",
        "def class_to_string (label):\n",
        "  galaxy = {\n",
        "      0: 'Barred Spiral', \n",
        "      1: 'Cigar Shaped Smooth', \n",
        "      2: 'Disturbed', \n",
        "      3: 'Edge-on with Bulge',\n",
        "      4: 'Edge-on without Bulge', \n",
        "      5: 'In-between Round Smooth', \n",
        "      6: 'Merging', \n",
        "      7: 'Round Smooth', \n",
        "      8: 'Unbarred Loose Spiral', \n",
        "      9: 'Unbarred Tight Spiral'\n",
        "    }\n",
        "  return galaxy[label]\n",
        "\n",
        "class galaxy_folder(torchvision.datasets.ImageFolder):\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "\n",
        "      path, target = self.samples[index]\n",
        "      sample = self.loader(path)\n",
        "      if self.transform is not None:\n",
        "          sample = self.transform(sample)\n",
        "      if self.target_transform is not None:\n",
        "         target = self.target_transform(target)\n",
        "\n",
        "      return sample, target, path\n",
        "\n",
        "\n",
        "def evaluate(yt, yp, num_classes=10):\n",
        "  C=(yt*num_classes+yp).bincount(minlength=num_classes**2).view(num_classes,num_classes).float()\n",
        "  return {\n",
        "      'Acc': C.diag().sum().item()/yt.shape[0],\n",
        "      'mAcc': (C.diag()/C.sum(-1)).mean().item(),\n",
        "      'mIoU': (C.diag()/(C.sum(0)+C.sum(1)-C.diag())).mean().item()\n",
        "  }\n",
        "\n",
        "def validate(model, metric_tracker, dataloader):\n",
        "  model.eval()\n",
        "  metric_tracker.clear()\n",
        "\n",
        "  with torch.no_grad(): \n",
        "    for i,(X,yt) in enumerate(dataloader):\n",
        "      X = X.cuda()\n",
        "      yt=yt.cuda()\n",
        "      Y = model(X)\n",
        "      y = Y.argmax(-1)\n",
        "\n",
        "      metric_tracker.add(y,yt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZk2HrQBCvA0"
      },
      "source": [
        "def train_one_epoch(model, loss_func, metric_tracker, dataloader, optimizer, epoch, tblog=None):\n",
        "  model.train()\n",
        "  metric_tracker.clear()  \n",
        "  model=model.cuda()\n",
        "  for i,(X,yt) in enumerate(dataloader):\n",
        "    X=X.cuda()\n",
        "    yt=yt.cuda()\n",
        "    optimizer.zero_grad()\n",
        "    Y = model(X)\n",
        "    loss = loss_func(Y, yt)\n",
        "    y = Y.argmax(-1)\n",
        "    metric_tracker.add(y, yt)\n",
        "    if tblog:\n",
        "      wandb.log({'loss': loss.item()})\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "def train(model, trDataLoader, vlDataLoader, optimizer, num_epochs, tblog=None):\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  metric_tracker = ClassificationMetrics(10)\n",
        "  best_net=0\n",
        "  model_save_name = 'secondTry.pt'\n",
        "  path = F\"pathtosavemodel/{model_save_name}\" \n",
        "  for epoch in range(1,num_epochs+1):\n",
        "\n",
        "    print(\"-- EPOCH {}/{} -------------------------\\n\".format(epoch, num_epochs))\n",
        "    train_one_epoch(model, loss_func, metric_tracker, trDataLoader, optimizer, epoch, tblog)\n",
        "\n",
        "    print(\"\\tTRAIN | acc: {:.4f} | mAcc: {:.4f} | mIoU: {:.4f}\".format(\n",
        "        metric_tracker.acc(), metric_tracker.mAcc(), metric_tracker.mIoU()\n",
        "    ))\n",
        "    \n",
        "    if tblog:\n",
        "      wandb.log({'Train/acc': metric_tracker.acc()})\n",
        "      wandb.log({'Train/mAcc': metric_tracker.mAcc()})\n",
        "      wandb.log({'Train/mIoU': metric_tracker.mIoU()})\n",
        "\n",
        "    validate(model, metric_tracker, vlDataLoader)\n",
        "\n",
        "    print(\"\\tEVAL  | acc: {:.4f} | mAcc: {:.4f} | mIoU: {:.4f}\\n\".format(\n",
        "        metric_tracker.acc(), \n",
        "        metric_tracker.mAcc(), metric_tracker.mIoU()\n",
        "    ))\n",
        "\n",
        "\n",
        "    if tblog:\n",
        "      wandb.log({'val/acc': metric_tracker.acc()})\n",
        "      wandb.log({'val/mAcc': metric_tracker.mAcc()} )\n",
        "      wandb.log({'val/mIoU': metric_tracker.mIoU()})\n",
        "\n",
        "    #save the best performing net in all the epochs\n",
        "    if metric_tracker.mIoU() >= best_net:\n",
        "      torch.save(model.state_dict(), path)\n",
        "      best_net = metric_tracker.mIoU()                                            con adam non dovrei dovermi preoccupare di cambiare il learning rate\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr_sc3lfC56Z"
      },
      "source": [
        "def load_data():\n",
        "  resized_normal = torchvision.transforms.Compose([\n",
        "      torchvision.transforms.Resize(224),\n",
        "      torchvision.transforms.ToTensor(),\n",
        "      torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                       std=[0.229, 0.224, 0.225])\n",
        "  ])\n",
        "\n",
        "  random_rot_transform = torchvision.transforms.Compose([\n",
        "      torchvision.transforms.Resize(224),\n",
        "      torchvision.transforms.RandomRotation((0, 360)),\n",
        "      torchvision.transforms.ToTensor(),\n",
        "      torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                       std=[0.229, 0.224, 0.225])\n",
        "  ])\n",
        "\n",
        "  centrer_crop = torchvision.transforms.Compose([\n",
        "      torchvision.transforms.CenterCrop(224),\n",
        "      torchvision.transforms.ToTensor(),\n",
        "      torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                       std=[0.229, 0.224, 0.225])\n",
        "  ])\n",
        "\n",
        "  data_center_cropped = torchvision.datasets.ImageFolder(path_dataset_train, transform=centrer_crop)\n",
        "  data_rand_rot = torchvision.datasets.ImageFolder(path_dataset_train, transform=random_rot_transform)\n",
        "  data_resized = torchvision.datasets.ImageFolder(path_dataset_train, transform=resized_normal)\n",
        "\n",
        "  tot_dataset = torch.utils.data.ConcatDataset([data_center_cropped, data_rand_rot, data_resized])\n",
        "\n",
        "\n",
        "  n_image = 12415*3\n",
        "  split = int(n_image*20/100)\n",
        "  print('total datset: {}\\ntraining set: {}\\nvalidation set: {}'.format(n_image, n_image - split, split))\n",
        "  # splitting the dataset in 80% for training and 20% for validation\n",
        "  vl_dataset, tr_dataset = data.random_split(tot_dataset, [split, n_image - split])\n",
        "\n",
        "\n",
        "  trDataLoader = torch.utils.data.DataLoader(tr_dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
        "  vlDataLoader = torch.utils.data.DataLoader(vl_dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
        "\n",
        "  return trDataLoader, vlDataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZblkbuogDq-c"
      },
      "source": [
        "#main\n",
        "\n",
        "rete = models.resnet18(pretrained=True)\n",
        "num_ftrs = rete.fc.in_features\n",
        "rete.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "trData, vlData = load_data()\n",
        "\n",
        "optim = torch.optim.Adam(rete.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "\n",
        "train(rete, trData, vlData, optim, 20, \"Resnet18\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
